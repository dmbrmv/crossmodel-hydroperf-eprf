{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a194b21",
   "metadata": {},
   "source": [
    "# Discharge Prediction with HBV Distributed Model (Hapi)\n",
    "\n",
    "This notebook demonstrates how to implement and run the distributed HBV hydrological model for discharge prediction using the Hapi (Hydrological library for Python) framework.\n",
    "\n",
    "The HBV model is a conceptual hydrological model developed by the Swedish Meteorological and Hydrological Institute (SMHI) that simulates catchment runoff by accounting for processes such as snow accumulation/melting, soil moisture, and runoff response. In this notebook, we use a distributed version that applies the model at the grid cell level.\n",
    "\n",
    "## Workflow Overview\n",
    "1. **Setup & Dependencies**\n",
    "2. **Data Preparation**\n",
    "   - Load digital elevation model (DEM)\n",
    "   - Prepare flow direction & accumulation data\n",
    "   - Load meteorological forcings (precipitation, temperature, evapotranspiration)\n",
    "   - Set up parameters\n",
    "3. **Model Configuration**\n",
    "4. **Model Execution**\n",
    "5. **Results Analysis & Visualization**\n",
    "6. **Model Evaluation**\n",
    "\n",
    "### References\n",
    "- BergstrÃ¶m, S. (1992). The HBV model - its structure and applications. SMHI Reports RH.\n",
    "- [Hapi GitHub Repository](https://github.com/Serapieum-of-alex/Hapi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743f583",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies\n",
    "\n",
    "First, we need to install and import the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Hapi if not already installed\n",
    "# Uncomment the following line to install\n",
    "# !pip install Hapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b543c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core dependencies\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Tuple, List, Optional, Union\n",
    "from datetime import datetime\n",
    "\n",
    "# Hapi modules\n",
    "from Hapi.rrm.distrrm import DistributedRRM\n",
    "from Hapi.rrm.hbv import HBV\n",
    "from Hapi.raster.raster import Raster\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92237d5",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "For the distributed HBV model, we need several input datasets:\n",
    "\n",
    "1. Digital Elevation Model (DEM)\n",
    "2. Flow direction and accumulation data\n",
    "3. Meteorological data (precipitation, temperature, evapotranspiration)\n",
    "4. Model parameters (can be calibrated or from literature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878228be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths (adjust according to your setup)\n",
    "data_dir = \"../data\"\n",
    "dem_path = os.path.join(data_dir, \"DEM/dem.tif\")\n",
    "\n",
    "# Path to meteorological data\n",
    "prec_path = os.path.join(data_dir, \"MeteoData/precipitation.nc\")\n",
    "temp_path = os.path.join(data_dir, \"MeteoData/temperature.nc\")\n",
    "et_path = os.path.join(data_dir, \"MeteoData/evapotranspiration.nc\")\n",
    "\n",
    "# Path to flow direction and accumulation files\n",
    "flow_dir_path = os.path.join(data_dir, \"Geometry/flow_direction.tif\")\n",
    "flow_acc_path = os.path.join(data_dir, \"Geometry/flow_accumulation.tif\")\n",
    "\n",
    "# Path to observed discharge data (for validation)\n",
    "observed_q_path = os.path.join(data_dir, \"HydroFiles/observed_discharge.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bc68a",
   "metadata": {},
   "source": [
    "### 2.1 Load and Process DEM\n",
    "\n",
    "The DEM is the foundation for our distributed model as it provides the topographic information needed for flow routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b5af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dem(dem_path: str) -> Tuple[np.ndarray, float, float]:\n",
    "    \"\"\"Load DEM and extract relevant properties.\n",
    "\n",
    "    Args:\n",
    "        dem_path: Path to DEM file\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing DEM array, cell size, and no data value\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load DEM\n",
    "        dem_raster = Raster(dem_path)\n",
    "        dem_array = dem_raster.read_array()\n",
    "        cell_size = dem_raster.cell_size\n",
    "        no_data_value = dem_raster.no_data_value\n",
    "\n",
    "        return dem_array, cell_size, no_data_value\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading DEM: {str(e)}\")\n",
    "        # Return dummy data for demonstration\n",
    "        return np.ones((100, 100)), 0.01, -9999\n",
    "\n",
    "\n",
    "# Try to load DEM\n",
    "try:\n",
    "    dem_array, cell_size, no_data_value = load_dem(dem_path)\n",
    "\n",
    "    # Create catchment mask\n",
    "    mask = np.where(dem_array != no_data_value, 1, 0)\n",
    "\n",
    "    # Display DEM information\n",
    "    print(f\"DEM Shape: {dem_array.shape}\")\n",
    "    print(f\"DEM Resolution: {cell_size}\")\n",
    "    print(f\"DEM No Data Value: {no_data_value}\")\n",
    "\n",
    "    # Visualize the DEM\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(dem_array, cmap=\"terrain\")\n",
    "    plt.colorbar(label=\"Elevation (m)\")\n",
    "    plt.title(\"Digital Elevation Model\")\n",
    "    plt.show()\n",
    "\n",
    "    # Store DEM path for model execution\n",
    "    DEM = dem_path\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DEM: {str(e)}\")\n",
    "    print(\"Using dummy DEM data for demonstration.\")\n",
    "    # Create dummy DEM for demonstration\n",
    "    dem_array = np.ones((100, 100))\n",
    "    cell_size = 0.01\n",
    "    no_data_value = -9999\n",
    "    mask = np.ones_like(dem_array)\n",
    "    DEM = \"dummy_dem.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94adb4c",
   "metadata": {},
   "source": [
    "### 2.2 Process Flow Direction and Accumulation Data\n",
    "\n",
    "Flow direction and accumulation maps are essential for routing the water through the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_flow_data(\n",
    "    flow_dir_path: str, flow_acc_path: str, dem_shape: Tuple[int, int]\n",
    ") -> Tuple[Dict, np.ndarray]:\n",
    "    \"\"\"Load flow direction and accumulation data.\n",
    "\n",
    "    Args:\n",
    "        flow_dir_path: Path to flow direction raster file\n",
    "        flow_acc_path: Path to flow accumulation raster file\n",
    "        dem_shape: Shape of the DEM (rows, cols)\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing flow accumulation dictionary and flow accumulation plan array\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # For demonstration, we'll create dummy flow accumulation data\n",
    "        # In a real application, you would load your prepared data\n",
    "\n",
    "        rows, cols = dem_shape\n",
    "\n",
    "        # Create dummy flow accumulation dictionary\n",
    "        # In practice, this would be derived from flow direction\n",
    "        flow_acc = {}\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                # Each cell drains to the cell below it (simplified)\n",
    "                if i < rows - 1:\n",
    "                    flow_acc[(i, j)] = [(i + 1, j)]\n",
    "\n",
    "        # Create dummy flow accumulation plan\n",
    "        flow_acc_plan = np.zeros(dem_shape, dtype=int)\n",
    "        # Simple accumulation pattern (cells accumulate from top to bottom)\n",
    "        for i in range(rows):\n",
    "            flow_acc_plan[i, :] = rows - i\n",
    "\n",
    "        logger.info(\"Flow direction and accumulation data prepared\")\n",
    "        return flow_acc, flow_acc_plan\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preparing flow data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Try to load flow data\n",
    "try:\n",
    "    flow_acc, flow_acc_plan = load_flow_data(flow_dir_path, flow_acc_path, dem_array.shape)\n",
    "    print(\"Flow direction and accumulation data prepared.\")\n",
    "\n",
    "    # Visualize flow accumulation\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(flow_acc_plan, cmap=\"Blues\")\n",
    "    plt.colorbar(label=\"Flow Accumulation\")\n",
    "    plt.title(\"Flow Accumulation Map\")\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing flow data: {str(e)}\")\n",
    "    print(\"Using dummy flow data for demonstration.\")\n",
    "    # Create minimal dummy flow data\n",
    "    flow_acc = {}\n",
    "    flow_acc_plan = np.ones_like(dem_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82929230",
   "metadata": {},
   "source": [
    "### 2.3 Load Meteorological Data\n",
    "\n",
    "For the HBV model, we need precipitation, temperature, and potential evapotranspiration data as forcing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05357f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meteorological_data(\n",
    "    prec_path: str, temp_path: str, et_path: str, dem_shape: Tuple[int, int]\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load and prepare meteorological data for the HBV model.\n",
    "\n",
    "    Args:\n",
    "        prec_path: Path to precipitation data\n",
    "        temp_path: Path to temperature data\n",
    "        et_path: Path to potential evapotranspiration data\n",
    "        dem_shape: Shape of the DEM (rows, cols)\n",
    "\n",
    "    Returns:\n",
    "        Tuple of 3D arrays for precipitation, temperature, and evapotranspiration\n",
    "        Each array has shape (rows, cols, timesteps)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # For demonstration, we'll create synthetic meteorological data\n",
    "        # In a real application, you would load your data files\n",
    "\n",
    "        rows, cols = dem_shape\n",
    "        n_timesteps = 365  # One year of daily data\n",
    "\n",
    "        # Create synthetic precipitation with seasonal pattern\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        sp_prec = np.zeros((rows, cols, n_timesteps))\n",
    "        for t in range(n_timesteps):\n",
    "            # Seasonal pattern with random noise\n",
    "            season_factor = np.sin(2 * np.pi * t / 365) + 1  # 0-2 range\n",
    "            daily_precip = np.random.exponential(scale=2 * season_factor, size=(rows, cols))\n",
    "            # Set some days to zero (dry days)\n",
    "            if np.random.random() < 0.7:  # 70% chance of rain\n",
    "                sp_prec[:, :, t] = daily_precip\n",
    "\n",
    "        # Create synthetic temperature with seasonal pattern\n",
    "        sp_temp = np.zeros((rows, cols, n_timesteps))\n",
    "        for t in range(n_timesteps):\n",
    "            # Temperature with seasonal pattern\n",
    "            base_temp = 15 + 10 * np.sin(2 * np.pi * t / 365)  # 5-25Â°C range\n",
    "            spatial_var = np.random.normal(0, 2, size=(rows, cols))\n",
    "            sp_temp[:, :, t] = base_temp + spatial_var\n",
    "\n",
    "        # Create synthetic evapotranspiration (correlated with temperature)\n",
    "        sp_et = np.zeros((rows, cols, n_timesteps))\n",
    "        for t in range(n_timesteps):\n",
    "            base_et = max(0, 0.5 + 0.2 * sp_temp[0, 0, t])\n",
    "            spatial_var = np.random.normal(0, 0.5, size=(rows, cols))\n",
    "            sp_et[:, :, t] = np.maximum(0, base_et + spatial_var)  # Ensure non-negative\n",
    "\n",
    "        return sp_prec, sp_temp, sp_et\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error preparing meteorological data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Try to load meteorological data\n",
    "try:\n",
    "    sp_prec, sp_temp, sp_et = load_meteorological_data(prec_path, temp_path, et_path, dem_array.shape)\n",
    "    print(f\"Meteorological data prepared with shape: {sp_prec.shape}\")\n",
    "\n",
    "    # Plot a time series at a random point for visualization\n",
    "    i, j = dem_array.shape[0] // 2, dem_array.shape[1] // 2  # Center point\n",
    "    time_range = range(sp_prec.shape[2])  # Time steps\n",
    "\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 10), sharex=True)\n",
    "\n",
    "    ax1.bar(time_range, sp_prec[i, j, :], color=\"blue\", alpha=0.7)\n",
    "    ax1.set_ylabel(\"Precipitation (mm)\")\n",
    "    ax1.set_title(\"Meteorological Data Time Series at Center Point\")\n",
    "\n",
    "    ax2.plot(time_range, sp_temp[i, j, :], color=\"red\")\n",
    "    ax2.set_ylabel(\"Temperature (Â°C)\")\n",
    "\n",
    "    ax3.plot(time_range, sp_et[i, j, :], color=\"green\")\n",
    "    ax3.set_ylabel(\"Pot. Evapotranspiration (mm)\")\n",
    "    ax3.set_xlabel(\"Time Step (days)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error preparing meteorological data: {str(e)}\")\n",
    "    # Create minimal dummy meteorological data\n",
    "    n_timesteps = 10\n",
    "    sp_prec = np.random.random((dem_array.shape[0], dem_array.shape[1], n_timesteps))\n",
    "    sp_temp = np.random.random((dem_array.shape[0], dem_array.shape[1], n_timesteps)) * 20\n",
    "    sp_et = np.random.random((dem_array.shape[0], dem_array.shape[1], n_timesteps)) * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff7f58",
   "metadata": {},
   "source": [
    "### 2.4 Prepare HBV Parameters\n",
    "\n",
    "The HBV model requires parameters for each grid cell. Parameters can be spatially distributed or uniform across the catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bf668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_hbv_parameters(dem_shape: Tuple[int, int]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Prepare spatially distributed HBV parameters.\n",
    "\n",
    "    Args:\n",
    "        dem_shape: Shape of the DEM (rows, cols)\n",
    "\n",
    "    Returns:\n",
    "        3D array of parameters with shape (rows, cols, n_params)\n",
    "    \"\"\"\n",
    "    # Number of HBV parameters\n",
    "    n_params = 10  # For the basic HBV model without snow\n",
    "\n",
    "    # Default parameter values based on literature\n",
    "    # These are sample values; in a real application, these would be calibrated\n",
    "    # Based on BergstrÃ¶m (1992) and Beck et al. (2016)\n",
    "    default_params = {\n",
    "        \"rfcf\": 1.0,  # Rainfall correction factor\n",
    "        \"fc\": 250.0,  # Field capacity (mm)\n",
    "        \"beta\": 3.0,  # Shape coefficient\n",
    "        \"etf\": 0.05,  # Total potential evapotranspiration factor\n",
    "        \"lp\": 0.3,  # Wilting point as fraction of fc\n",
    "        \"c_flux\": 0.01,  # Capillary flux coefficient\n",
    "        \"k\": 0.03,  # Upper zone recession coefficient\n",
    "        \"k1\": 0.01,  # Lower zone recession coefficient\n",
    "        \"alpha\": 0.3,  # Response box parameter\n",
    "        \"perc\": 0.8,  # Percolation rate (mm/day)\n",
    "    }\n",
    "\n",
    "    # Create a spatially distributed parameter array\n",
    "    rows, cols = dem_shape\n",
    "    sp_pars = np.zeros((rows, cols, n_params))\n",
    "\n",
    "    # Fill the parameter array with default values\n",
    "    # In a real application, you might vary these based on land cover, soil type, etc.\n",
    "    param_indices = list(default_params.keys())\n",
    "\n",
    "    for i, param_name in enumerate(param_indices):\n",
    "        # Create a bit of spatial variability (Â±10% of default value)\n",
    "        base_value = default_params[param_name]\n",
    "        variation = np.random.uniform(0.9 * base_value, 1.1 * base_value, size=(rows, cols))\n",
    "        sp_pars[:, :, i] = variation\n",
    "\n",
    "    return sp_pars\n",
    "\n",
    "\n",
    "# Prepare HBV parameters\n",
    "sp_pars = prepare_hbv_parameters(dem_array.shape)\n",
    "print(f\"HBV parameters prepared with shape: {sp_pars.shape}\")\n",
    "\n",
    "# Display parameter statistics\n",
    "param_names = [\"rfcf\", \"fc\", \"beta\", \"etf\", \"lp\", \"c_flux\", \"k\", \"k1\", \"alpha\", \"perc\"]\n",
    "\n",
    "for i, param in enumerate(param_names):\n",
    "    mean_val = np.mean(sp_pars[:, :, i])\n",
    "    min_val = np.min(sp_pars[:, :, i])\n",
    "    max_val = np.max(sp_pars[:, :, i])\n",
    "    print(f\"{param}: mean={mean_val:.4f}, min={min_val:.4f}, max={max_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a0d639",
   "metadata": {},
   "source": [
    "### 2.5 Define Additional Model Parameters\n",
    "\n",
    "Set up additional parameters needed for the HBV distributed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4214013c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Lake parameters (if lakes are present in the catchment)\n",
    "lakecell = None  # Tuple of lake cell coordinates (row, col)\n",
    "q_lake = None  # Time series of lake inflow\n",
    "\n",
    "# Time factor and catchment area\n",
    "tfac = 24  # Time step in hours (24 hours = daily data)\n",
    "area = 100  # Catchment area in square kilometers\n",
    "\n",
    "# Additional parameters for the HBV model\n",
    "p2 = [tfac, area]\n",
    "\n",
    "# Initial states (optional)\n",
    "init_st = None  # If None, default values will be used\n",
    "\n",
    "# Long-term mean temperature (optional)\n",
    "ll_temp = None  # If None, calculated from the temperature data\n",
    "\n",
    "# Initial discharge (optional)\n",
    "q_0 = None  # If None, a default value will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b6bc0",
   "metadata": {},
   "source": [
    "## 3. Initialize the HBV Model\n",
    "\n",
    "Now we'll create an instance of the HBV conceptual model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the HBV conceptual model\n",
    "conceptual_model = HBV()\n",
    "print(\"HBV conceptual model initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b58a8b",
   "metadata": {},
   "source": [
    "## 4. Run the Distributed HBV Model\n",
    "\n",
    "Now we'll execute the distributed HBV model using the prepared inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_distributed_hbv(\n",
    "    conceptual_model: HBV,\n",
    "    lakecell: Optional[Tuple[int, int]],\n",
    "    q_lake: Optional[np.ndarray],\n",
    "    DEM: str,\n",
    "    flow_acc: Dict,\n",
    "    flow_acc_plan: np.ndarray,\n",
    "    sp_prec: np.ndarray,\n",
    "    sp_et: np.ndarray,\n",
    "    sp_temp: np.ndarray,\n",
    "    sp_pars: np.ndarray,\n",
    "    p2: List[float],\n",
    "    init_st: Optional[List] = None,\n",
    "    ll_temp: Optional[np.ndarray] = None,\n",
    "    q_0: Optional[float] = None,\n",
    ") -> Tuple[np.ndarray, List, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Run the distributed HBV model.\n",
    "\n",
    "    Args:\n",
    "        conceptual_model: Instance of HBV class\n",
    "        lakecell: Tuple of lake cell coordinates (optional)\n",
    "        q_lake: Array of lake inflow (optional)\n",
    "        DEM: Path to DEM file\n",
    "        flow_acc: Dictionary mapping cell indices to upstream cells\n",
    "        flow_acc_plan: 2D array of flow accumulation plan\n",
    "        sp_prec: 3D array of precipitation (x, y, t)\n",
    "        sp_et: 3D array of potential evapotranspiration (x, y, t)\n",
    "        sp_temp: 3D array of temperature (x, y, t)\n",
    "        sp_pars: 3D array of HBV parameters (x, y, n_params)\n",
    "        p2: List [tfac, area]\n",
    "        init_st: Initial states (optional)\n",
    "        ll_temp: Long-term mean temperature (optional)\n",
    "        q_0: Initial discharge (optional)\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing outlet discharge, states, routed upper zone Q, lower zone Q, and upper zone Q\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(\"Starting distributed HBV model simulation...\")\n",
    "\n",
    "        # Call the Dist_HBV2 function from DistributedRRM\n",
    "        qout, st, quz_routed, qlz, quz = DistributedRRM.Dist_HBV2(\n",
    "            conceptual_model=conceptual_model,\n",
    "            lakecell=lakecell,\n",
    "            q_lake=q_lake,\n",
    "            DEM=DEM,\n",
    "            flow_acc=flow_acc,\n",
    "            flow_acc_plan=flow_acc_plan,\n",
    "            sp_prec=sp_prec,\n",
    "            sp_et=sp_et,\n",
    "            sp_temp=sp_temp,\n",
    "            sp_pars=sp_pars,\n",
    "            p2=p2,\n",
    "            init_st=init_st,\n",
    "            ll_temp=ll_temp,\n",
    "            q_0=q_0,\n",
    "        )\n",
    "\n",
    "        logger.info(\"Distributed HBV model simulation completed successfully\")\n",
    "        return qout, st, quz_routed, qlz, quz\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running distributed HBV model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "# Run the distributed HBV model\n",
    "try:\n",
    "    print(\"Starting HBV distributed model simulation...\")\n",
    "    qout, st, quz_routed, qlz, quz = run_distributed_hbv(\n",
    "        conceptual_model=conceptual_model,\n",
    "        lakecell=lakecell,\n",
    "        q_lake=q_lake,\n",
    "        DEM=DEM,\n",
    "        flow_acc=flow_acc,\n",
    "        flow_acc_plan=flow_acc_plan,\n",
    "        sp_prec=sp_prec,\n",
    "        sp_et=sp_et,\n",
    "        sp_temp=sp_temp,\n",
    "        sp_pars=sp_pars,\n",
    "        p2=p2,\n",
    "        init_st=init_st,\n",
    "        ll_temp=ll_temp,\n",
    "        q_0=q_0,\n",
    "    )\n",
    "    print(\"HBV distributed model simulation completed.\")\n",
    "    print(f\"Simulated discharge shape: {qout.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error running HBV model: {str(e)}\")\n",
    "    print(\"Using synthetic discharge data for demonstration...\")\n",
    "    # Create synthetic discharge for demonstration\n",
    "    n_timesteps = sp_prec.shape[2] if hasattr(sp_prec, \"shape\") else 365\n",
    "\n",
    "    # Simple synthetic discharge with seasonal pattern\n",
    "    time = np.arange(n_timesteps)\n",
    "    base = 20 + 15 * np.sin(2 * np.pi * time / 365)  # Seasonal pattern\n",
    "    noise = np.random.normal(0, 5, n_timesteps)  # Random variations\n",
    "    qout = np.maximum(0, base + noise)  # Ensure non-negative\n",
    "\n",
    "    # Dummy state variables and flow components\n",
    "    st = [[0, 0, 0, 0, 0] for _ in range(n_timesteps)]  # Dummy states\n",
    "    quz_routed = qout * 0.7  # Dummy upper zone routed component\n",
    "    qlz = qout * 0.3  # Dummy lower zone component\n",
    "    quz = qout * 0.7  # Dummy upper zone component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d381a8",
   "metadata": {},
   "source": [
    "## 5. Results Analysis & Visualization\n",
    "\n",
    "Now we'll analyze and visualize the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9bf918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the simulated discharge\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Time axis\n",
    "time_steps = np.arange(len(qout))\n",
    "\n",
    "# Plot discharge components\n",
    "plt.plot(time_steps, qout, \"b-\", linewidth=2, label=\"Total Discharge\")\n",
    "plt.plot(time_steps, quz_routed, \"g-\", alpha=0.7, label=\"Upper Zone (Routed)\")\n",
    "plt.plot(time_steps, qlz, \"r-\", alpha=0.7, label=\"Lower Zone\")\n",
    "\n",
    "plt.title(\"Simulated Discharge at Catchment Outlet\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Discharge (mÂ³/s)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec667b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked area chart of discharge components\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create stacked area chart\n",
    "plt.fill_between(time_steps, 0, qlz, color=\"darkblue\", alpha=0.7, label=\"Lower Zone (Baseflow)\")\n",
    "plt.fill_between(time_steps, qlz, qout, color=\"skyblue\", alpha=0.7, label=\"Upper Zone (Quick Flow)\")\n",
    "\n",
    "# Add total discharge line\n",
    "plt.plot(time_steps, qout, \"k-\", linewidth=1, label=\"Total Discharge\")\n",
    "\n",
    "plt.title(\"Discharge Components\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Discharge (mÂ³/s)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f704785",
   "metadata": {},
   "source": [
    "### 5.1 Water Balance Analysis\n",
    "\n",
    "Let's analyze the water balance components over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract catchment average precipitation and evapotranspiration\n",
    "# Calculate catchment average for each time step\n",
    "avg_prec = np.mean(sp_prec, axis=(0, 1))\n",
    "avg_et = np.mean(sp_et, axis=(0, 1))\n",
    "\n",
    "# Convert discharge from mÂ³/s to mm/day for water balance comparison\n",
    "# Q (mÂ³/s) to Q (mm/day) = Q * 86400 / (area_kmÂ² * 10^6) * 1000\n",
    "# Simplified: Q * 86.4 / area_kmÂ²\n",
    "q_mm = qout * 86.4 / area\n",
    "\n",
    "# Plot water balance components\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Precipitation and Discharge\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.bar(time_steps, avg_prec, color=\"blue\", alpha=0.5, label=\"Precipitation\")\n",
    "plt.plot(time_steps, q_mm, \"r-\", linewidth=2, label=\"Discharge\")\n",
    "plt.ylabel(\"Water Flux (mm/day)\")\n",
    "plt.legend()\n",
    "plt.title(\"Water Balance Components\")\n",
    "\n",
    "# Subplot 2: Evapotranspiration\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(time_steps, avg_et, color=\"green\", alpha=0.5, label=\"Pot. Evapotranspiration\")\n",
    "plt.ylabel(\"ET (mm/day)\")\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 3: Cumulative balance\n",
    "plt.subplot(3, 1, 3)\n",
    "cum_prec = np.cumsum(avg_prec)\n",
    "cum_q = np.cumsum(q_mm)\n",
    "cum_et = np.cumsum(avg_et)\n",
    "\n",
    "# Simplified storage change = P - Q - ET\n",
    "storage_change = cum_prec - cum_q - cum_et\n",
    "\n",
    "plt.plot(time_steps, cum_prec, \"b-\", linewidth=2, label=\"Cum. Precipitation\")\n",
    "plt.plot(time_steps, cum_q, \"r-\", linewidth=2, label=\"Cum. Discharge\")\n",
    "plt.plot(time_steps, cum_et, \"g-\", linewidth=2, label=\"Cum. ET\")\n",
    "plt.plot(time_steps, storage_change, \"k--\", linewidth=1.5, label=\"Storage Change\")\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Cumulative Water (mm)\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2b606",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation\n",
    "\n",
    "If observed discharge data is available, we can evaluate the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d77f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(sim_q: np.ndarray, obs_q: np.ndarray) -> Dict[str, float]:\n",
    "    \"\"\"Evaluate the model performance using common hydrological metrics.\n",
    "\n",
    "    Args:\n",
    "        sim_q: Simulated discharge time series\n",
    "        obs_q: Observed discharge time series\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    # Ensure arrays are the same length\n",
    "    min_len = min(len(sim_q), len(obs_q))\n",
    "    sim_q = sim_q[:min_len]\n",
    "    obs_q = obs_q[:min_len]\n",
    "\n",
    "    # Nash-Sutcliffe Efficiency (NSE)\n",
    "    # NSE = 1 - â(Qobs - Qsim)Â² / â(Qobs - mean(Qobs))Â²\n",
    "    mean_obs = np.mean(obs_q)\n",
    "    nse_numerator = np.sum((obs_q - sim_q) ** 2)\n",
    "    nse_denominator = np.sum((obs_q - mean_obs) ** 2)\n",
    "    nse = 1 - (nse_numerator / nse_denominator)\n",
    "\n",
    "    # Kling-Gupta Efficiency (KGE)\n",
    "    # KGE = 1 - â[(r-1)Â² + (Î±-1)Â² + (Î²-1)Â²]\n",
    "    # where r is correlation coefficient, Î± is the ratio of std devs, Î² is the ratio of means\n",
    "    r = np.corrcoef(sim_q, obs_q)[0, 1]\n",
    "    alpha = np.std(sim_q) / np.std(obs_q)\n",
    "    beta = np.mean(sim_q) / mean_obs\n",
    "    kge = 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "\n",
    "    # Root Mean Square Error (RMSE)\n",
    "    rmse = np.sqrt(np.mean((sim_q - obs_q) ** 2))\n",
    "\n",
    "    # Mean Absolute Error (MAE)\n",
    "    mae = np.mean(np.abs(sim_q - obs_q))\n",
    "\n",
    "    # Percent Bias (PBIAS)\n",
    "    pbias = 100 * np.sum(sim_q - obs_q) / np.sum(obs_q)\n",
    "\n",
    "    # Return metrics dictionary\n",
    "    metrics = {\"NSE\": nse, \"KGE\": kge, \"RMSE\": rmse, \"MAE\": mae, \"PBIAS\": pbias}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Create synthetic \"observed\" data for demonstration\n",
    "observed_q = qout * (1 + 0.2 * np.random.normal(0, 1, len(qout)))  # Add some noise\n",
    "observed_q = np.maximum(0, observed_q)  # Ensure non-negative\n",
    "\n",
    "# Evaluate model performance\n",
    "metrics = evaluate_model(qout, observed_q)\n",
    "\n",
    "print(\"Model Evaluation Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "# Plot observed vs simulated discharge\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(time_steps, observed_q, \"k-\", label=\"Observed\")\n",
    "plt.plot(time_steps, qout, \"r-\", label=\"Simulated\")\n",
    "plt.fill_between(\n",
    "    time_steps,\n",
    "    observed_q,\n",
    "    qout,\n",
    "    where=(observed_q > qout),\n",
    "    interpolate=True,\n",
    "    color=\"blue\",\n",
    "    alpha=0.3,\n",
    "    label=\"Underestimation\",\n",
    ")\n",
    "plt.fill_between(\n",
    "    time_steps,\n",
    "    observed_q,\n",
    "    qout,\n",
    "    where=(observed_q <= qout),\n",
    "    interpolate=True,\n",
    "    color=\"red\",\n",
    "    alpha=0.3,\n",
    "    label=\"Overestimation\",\n",
    ")\n",
    "plt.title(\"Observed vs Simulated Discharge\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Discharge (mÂ³/s)\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcfe556",
   "metadata": {},
   "source": [
    "## 7. Summary and Conclusions\n",
    "\n",
    "We have demonstrated the workflow for setting up and running a distributed HBV model for discharge prediction using the Hapi framework. The key steps include:\n",
    "\n",
    "1. **Data preparation**: Loading and processing DEM, flow direction/accumulation, meteorological data, and parameter fields.\n",
    "\n",
    "2. **Model initialization**: Creating an instance of the HBV conceptual model.\n",
    "\n",
    "3. **Model execution**: Running the distributed HBV model using the `Dist_HBV2` function from the `DistributedRRM` class.\n",
    "\n",
    "4. **Results analysis**: Visualizing and analyzing the simulated discharge and its components.\n",
    "\n",
    "5. **Model evaluation**: Assessing model performance using common hydrological metrics like NSE and KGE.\n",
    "\n",
    "This approach allows for spatially distributed simulation of hydrological processes across a catchment, accounting for spatial variability in topography, meteorological forcing, and model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69fe13e",
   "metadata": {},
   "source": [
    "## 8. Parameter Calibration with Optuna\n",
    "\n",
    "In hydrological modeling, parameter calibration is crucial for achieving good model performance. Here, we'll use Optuna, a hyperparameter optimization framework, to calibrate the HBV model parameters.\n",
    "\n",
    "Optuna provides several advantages:\n",
    "- Efficient parameter space exploration\n",
    "- Support for various sampling strategies (TPE, CMA-ES, etc.)\n",
    "- Parallel computing capabilities\n",
    "- Trial pruning for early stopping of unpromising trials\n",
    "- Visualization tools for understanding parameter importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d07fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Optuna if not already installed\n",
    "# Uncomment the following line to install\n",
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff07945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Optuna and additional required libraries\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# Set up separate logger for the calibration process\n",
    "calib_logger = logging.getLogger(\"hbv_calibration\")\n",
    "calib_logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a678525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_objective_function(\n",
    "    dem_shape: Tuple[int, int],\n",
    "    conceptual_model: HBV,\n",
    "    dem_path: str,\n",
    "    flow_acc: Dict,\n",
    "    flow_acc_plan: np.ndarray,\n",
    "    sp_prec: np.ndarray,\n",
    "    sp_et: np.ndarray,\n",
    "    sp_temp: np.ndarray,\n",
    "    p2: List[float],\n",
    "    observed_q: np.ndarray,\n",
    "    param_ranges: Optional[Dict[str, Tuple[float, float]]] = None,\n",
    "    objective_metric: str = \"KGE\",\n",
    "    lakecell: Optional[Tuple[int, int]] = None,\n",
    "    q_lake: Optional[np.ndarray] = None,\n",
    "    init_st: Optional[List] = None,\n",
    "    ll_temp: Optional[np.ndarray] = None,\n",
    "    q_0: Optional[float] = None,\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    Create an objective function for Optuna parameter optimization.\n",
    "\n",
    "    Args:\n",
    "        dem_shape: Shape of the DEM (rows, cols)\n",
    "        conceptual_model: Instance of HBV class\n",
    "        dem_path: Path to DEM file\n",
    "        flow_acc: Dictionary mapping cell indices to upstream cells\n",
    "        flow_acc_plan: 2D array of flow accumulation plan\n",
    "        sp_prec: 3D array of precipitation (x, y, t)\n",
    "        sp_et: 3D array of potential evapotranspiration (x, y, t)\n",
    "        sp_temp: 3D array of temperature (x, y, t)\n",
    "        p2: List [tfac, area]\n",
    "        observed_q: Observed discharge for calibration\n",
    "        param_ranges: Dictionary with parameter ranges (min, max) for calibration\n",
    "        objective_metric: Metric to optimize (\"KGE\", \"NSE\", \"RMSE\", \"MAE\")\n",
    "        lakecell: Tuple of lake cell coordinates (optional)\n",
    "        q_lake: Array of lake inflow (optional)\n",
    "        init_st: Initial states (optional)\n",
    "        ll_temp: Long-term mean temperature (optional)\n",
    "        q_0: Initial discharge (optional)\n",
    "\n",
    "    Returns:\n",
    "        Objective function for Optuna optimization\n",
    "    \"\"\"\n",
    "    # Default parameter ranges if not provided\n",
    "    if param_ranges is None:\n",
    "        param_ranges = {\n",
    "            \"rfcf\": (0.5, 2.0),  # Rainfall correction factor\n",
    "            \"fc\": (50.0, 500.0),  # Field capacity (mm)\n",
    "            \"beta\": (1.0, 6.0),  # Shape coefficient\n",
    "            \"etf\": (0.01, 0.5),  # Total potential evapotranspiration factor\n",
    "            \"lp\": (0.1, 0.9),  # Wilting point as fraction of fc\n",
    "            \"c_flux\": (0.0, 0.1),  # Capillary flux coefficient\n",
    "            \"k\": (0.01, 0.5),  # Upper zone recession coefficient\n",
    "            \"k1\": (0.001, 0.1),  # Lower zone recession coefficient\n",
    "            \"alpha\": (0.1, 0.9),  # Response box parameter\n",
    "            \"perc\": (0.1, 1.0),  # Percolation rate (mm/day)\n",
    "        }\n",
    "\n",
    "    param_names = list(param_ranges.keys())\n",
    "\n",
    "    def objective(trial: optuna.Trial) -> float:\n",
    "        # Generate parameters using Optuna's suggest functions\n",
    "        trial_params = {}\n",
    "        for param_name in param_names:\n",
    "            param_min, param_max = param_ranges[param_name]\n",
    "            trial_params[param_name] = trial.suggest_float(param_name, param_min, param_max)\n",
    "\n",
    "        calib_logger.info(f\"Trial {trial.number}: {trial_params}\")\n",
    "\n",
    "        # Create parameter array with spatially uniform parameters for this trial\n",
    "        rows, cols = dem_shape\n",
    "        sp_pars = np.zeros((rows, cols, len(param_names)))\n",
    "\n",
    "        # Fill parameter array with trial parameters (uniform across catchment for simplicity)\n",
    "        for i, param_name in enumerate(param_names):\n",
    "            sp_pars[:, :, i] = trial_params[param_name]\n",
    "\n",
    "        try:\n",
    "            # Run HBV model with trial parameters\n",
    "            qout, _, _, _, _ = run_distributed_hbv(\n",
    "                conceptual_model=conceptual_model,\n",
    "                lakecell=lakecell,\n",
    "                q_lake=q_lake,\n",
    "                DEM=dem_path,\n",
    "                flow_acc=flow_acc,\n",
    "                flow_acc_plan=flow_acc_plan,\n",
    "                sp_prec=sp_prec,\n",
    "                sp_et=sp_et,\n",
    "                sp_temp=sp_temp,\n",
    "                sp_pars=sp_pars,\n",
    "                p2=p2,\n",
    "                init_st=init_st,\n",
    "                ll_temp=ll_temp,\n",
    "                q_0=q_0,\n",
    "            )\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            metrics = evaluate_model(qout, observed_q)\n",
    "\n",
    "            # Return the objective value (negative because Optuna minimizes)\n",
    "            if objective_metric == \"KGE\":\n",
    "                return -metrics[\"KGE\"]\n",
    "            elif objective_metric == \"NSE\":\n",
    "                return -metrics[\"NSE\"]\n",
    "            elif objective_metric == \"RMSE\":\n",
    "                return metrics[\"RMSE\"]\n",
    "            elif objective_metric == \"MAE\":\n",
    "                return metrics[\"MAE\"]\n",
    "            else:\n",
    "                return -metrics[\"KGE\"]  # Default to KGE\n",
    "\n",
    "        except Exception as e:\n",
    "            calib_logger.error(f\"Error in trial {trial.number}: {str(e)}\")\n",
    "            # Return a poor score for failed trials\n",
    "            if objective_metric in [\"KGE\", \"NSE\"]:\n",
    "                return -999.0  # For metrics where higher is better (using negative)\n",
    "            else:\n",
    "                return 999.0  # For metrics where lower is better\n",
    "\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6164572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_optuna_calibration(\n",
    "    objective_function: Callable,\n",
    "    n_trials: int = 100,\n",
    "    n_jobs: int = 1,\n",
    "    direction: str = \"minimize\",\n",
    "    study_name: str = \"hbv_calibration\",\n",
    "    storage: Optional[str] = None,\n",
    "    sampler: Optional[optuna.samplers.BaseSampler] = None,\n",
    ") -> optuna.study.Study:\n",
    "    \"\"\"\n",
    "    Run Optuna optimization for parameter calibration.\n",
    "\n",
    "    Args:\n",
    "        objective_function: Objective function for optimization\n",
    "        n_trials: Number of trials to run\n",
    "        n_jobs: Number of parallel jobs\n",
    "        direction: Direction of optimization (\"minimize\" or \"maximize\")\n",
    "        study_name: Name of the study\n",
    "        storage: Database URL for storing study results (optional)\n",
    "        sampler: Optuna sampler to use (optional)\n",
    "\n",
    "    Returns:\n",
    "        Completed Optuna study object\n",
    "    \"\"\"\n",
    "    # Create sampler if not provided\n",
    "    if sampler is None:\n",
    "        sampler = optuna.samplers.TPESampler(seed=42)\n",
    "\n",
    "    # Create study\n",
    "    study = optuna.create_study(\n",
    "        direction=direction, study_name=study_name, storage=storage, sampler=sampler, load_if_exists=True\n",
    "    )\n",
    "\n",
    "    # Run optimization\n",
    "    start_time = datetime.now()\n",
    "    print(f\"Starting parameter calibration with {n_trials} trials...\")\n",
    "    study.optimize(objective_function, n_trials=n_trials, n_jobs=n_jobs)\n",
    "    end_time = datetime.now()\n",
    "\n",
    "    # Print results\n",
    "    print(f\"\\nCalibration completed in {end_time - start_time}\")\n",
    "    print(f\"Best trial: #{study.best_trial.number}\")\n",
    "    print(f\"Best value: {-study.best_value if direction == 'minimize' else study.best_value}\")\n",
    "    print(\"\\nBest parameters:\")\n",
    "    for param_name, param_value in study.best_params.items():\n",
    "        print(f\"  {param_name}: {param_value:.6f}\")\n",
    "\n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Set up HBV calibration with Optuna\n",
    "# Note: This is a demonstration; in practice you would use real observed data\n",
    "\n",
    "\n",
    "def run_calibration_example(\n",
    "    use_real_optimization: bool = False,  # Set to True to run full optimization (time-consuming)\n",
    "    n_trials: int = 5,  # Use a small number for demonstration\n",
    "    n_jobs: int = 1,  # Use 1 for demonstration\n",
    "):\n",
    "    # Ensure we have all required data\n",
    "    if \"sp_prec\" not in globals() or \"observed_q\" not in globals():\n",
    "        print(\"Error: Required data variables not found.\")\n",
    "        return None\n",
    "\n",
    "    # Parameter ranges to explore\n",
    "    param_ranges = {\n",
    "        \"rfcf\": (0.7, 1.5),  # Rainfall correction factor\n",
    "        \"fc\": (100.0, 400.0),  # Field capacity (mm)\n",
    "        \"beta\": (1.5, 5.0),  # Shape coefficient\n",
    "        \"etf\": (0.05, 0.3),  # Total potential evapotranspiration factor\n",
    "        \"lp\": (0.2, 0.8),  # Wilting point as fraction of fc\n",
    "        \"c_flux\": (0.0, 0.05),  # Capillary flux coefficient\n",
    "        \"k\": (0.01, 0.2),  # Upper zone recession coefficient\n",
    "        \"k1\": (0.005, 0.05),  # Lower zone recession coefficient\n",
    "        \"alpha\": (0.2, 0.8),  # Response box parameter\n",
    "        \"perc\": (0.3, 0.9),  # Percolation rate (mm/day)\n",
    "    }\n",
    "\n",
    "    # Create objective function\n",
    "    objective_fn = create_objective_function(\n",
    "        dem_shape=dem_array.shape,\n",
    "        conceptual_model=conceptual_model,\n",
    "        dem_path=DEM,\n",
    "        flow_acc=flow_acc,\n",
    "        flow_acc_plan=flow_acc_plan,\n",
    "        sp_prec=sp_prec,\n",
    "        sp_et=sp_et,\n",
    "        sp_temp=sp_temp,\n",
    "        p2=p2,\n",
    "        observed_q=observed_q,\n",
    "        param_ranges=param_ranges,\n",
    "        objective_metric=\"KGE\",  # Optimize for Kling-Gupta Efficiency\n",
    "    )\n",
    "\n",
    "    if use_real_optimization:\n",
    "        # Run optimization\n",
    "        study = run_optuna_calibration(\n",
    "            objective_function=objective_fn,\n",
    "            n_trials=n_trials,\n",
    "            n_jobs=n_jobs,\n",
    "            direction=\"minimize\",  # We're minimizing negative KGE\n",
    "        )\n",
    "        return study\n",
    "    else:\n",
    "        print(\n",
    "            \"Calibration setup is complete. Set use_real_optimization=True to run actual optimization.\"\n",
    "        )\n",
    "        print(\n",
    "            \"Note: Actual calibration can be time-consuming depending on catchment size and number of trials.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "# Set up the calibration (but don't run it by default to avoid long execution)\n",
    "calibration_setup = run_calibration_example(use_real_optimization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74ee0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize Optuna results\n",
    "def visualize_optuna_results(study: optuna.study.Study):\n",
    "    \"\"\"Visualize the results of Optuna parameter calibration.\"\"\"\n",
    "    if study is None:\n",
    "        print(\"No study to visualize. Run the optimization first.\")\n",
    "        return\n",
    "\n",
    "    # Importance of each parameter\n",
    "    try:\n",
    "        param_importance = optuna.importance.get_param_importances(study)\n",
    "\n",
    "        # Plot parameter importance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        importance_df = pd.DataFrame(\n",
    "            list(param_importance.items()), columns=[\"Parameter\", \"Importance\"]\n",
    "        ).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "        bars = plt.bar(importance_df[\"Parameter\"], importance_df[\"Importance\"], color=\"skyblue\")\n",
    "        plt.title(\"Parameter Importance\")\n",
    "        plt.xlabel(\"Parameter\")\n",
    "        plt.ylabel(\"Importance Score\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(axis=\"y\", alpha=0.3)\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width() / 2.0,\n",
    "                height + 0.01,\n",
    "                f\"{height:.3f}\",\n",
    "                ha=\"center\",\n",
    "                va=\"bottom\",\n",
    "            )\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not calculate parameter importance: {str(e)}\")\n",
    "\n",
    "    # Plot optimization history\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(\n",
    "        [t.number for t in study.trials],\n",
    "        [-t.value for t in study.trials],  # Convert back from negative\n",
    "        \"o-\",\n",
    "        alpha=0.6,\n",
    "    )\n",
    "    plt.axhline(y=-study.best_value, color=\"r\", linestyle=\"--\", label=\"Best Value\")\n",
    "    plt.title(\"Optimization History\")\n",
    "    plt.xlabel(\"Trial Number\")\n",
    "    plt.ylabel(\"Objective Value (KGE)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Try to generate contour plots for pairs of important parameters\n",
    "    try:\n",
    "        # Plot contour plots for parameter combinations\n",
    "        fig = optuna.visualization.plot_contour(study)\n",
    "        fig.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate contour plots: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb554468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply calibrated parameters and evaluate model performance\n",
    "def apply_calibrated_parameters(\n",
    "    study: optuna.study.Study,\n",
    "    dem_shape: Tuple[int, int],\n",
    "    conceptual_model: HBV,\n",
    "    dem_path: str,\n",
    "    flow_acc: Dict,\n",
    "    flow_acc_plan: np.ndarray,\n",
    "    sp_prec: np.ndarray,\n",
    "    sp_et: np.ndarray,\n",
    "    sp_temp: np.ndarray,\n",
    "    p2: List[float],\n",
    "    observed_q: np.ndarray,\n",
    "    lakecell: Optional[Tuple[int, int]] = None,\n",
    "    q_lake: Optional[np.ndarray] = None,\n",
    "    init_st: Optional[List] = None,\n",
    "    ll_temp: Optional[np.ndarray] = None,\n",
    "    q_0: Optional[float] = None,\n",
    "):\n",
    "    \"\"\"Apply calibrated parameters and evaluate model performance.\"\"\"\n",
    "    if study is None:\n",
    "        print(\"No calibration study available.\")\n",
    "        return\n",
    "\n",
    "    # Extract best parameters\n",
    "    best_params = study.best_params\n",
    "    print(\"\\nRunning model with calibrated parameters:\")\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value:.6f}\")\n",
    "\n",
    "    # Create parameter array with calibrated values\n",
    "    param_names = list(best_params.keys())\n",
    "    rows, cols = dem_shape\n",
    "    sp_pars_calibrated = np.zeros((rows, cols, len(param_names)))\n",
    "\n",
    "    for i, param_name in enumerate(param_names):\n",
    "        sp_pars_calibrated[:, :, i] = best_params[param_name]\n",
    "\n",
    "    # Run model with calibrated parameters\n",
    "    qout_calibrated, st_calibrated, quz_routed_calibrated, qlz_calibrated, quz_calibrated = (\n",
    "        run_distributed_hbv(\n",
    "            conceptual_model=conceptual_model,\n",
    "            lakecell=lakecell,\n",
    "            q_lake=q_lake,\n",
    "            DEM=dem_path,\n",
    "            flow_acc=flow_acc,\n",
    "            flow_acc_plan=flow_acc_plan,\n",
    "            sp_prec=sp_prec,\n",
    "            sp_et=sp_et,\n",
    "            sp_temp=sp_temp,\n",
    "            sp_pars=sp_pars_calibrated,\n",
    "            p2=p2,\n",
    "            init_st=init_st,\n",
    "            ll_temp=ll_temp,\n",
    "            q_0=q_0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    metrics_calibrated = evaluate_model(qout_calibrated, observed_q)\n",
    "\n",
    "    print(\"\\nPerformance metrics with calibrated parameters:\")\n",
    "    for metric, value in metrics_calibrated.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "    # Plot results\n",
    "    time_steps = np.arange(len(observed_q))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(time_steps, observed_q, \"k-\", label=\"Observed\")\n",
    "    plt.plot(time_steps, qout_calibrated, \"r-\", label=\"Calibrated Model\")\n",
    "\n",
    "    plt.title(\"Calibrated HBV Model Performance\")\n",
    "    plt.xlabel(\"Time Step\")\n",
    "    plt.ylabel(\"Discharge (mÂ³/s)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return calibrated outputs\n",
    "    return qout_calibrated, st_calibrated, quz_routed_calibrated, qlz_calibrated, quz_calibrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf652fe8",
   "metadata": {},
   "source": [
    "### Running a Full Calibration\n",
    "\n",
    "To run a full calibration process with your real data:\n",
    "\n",
    "1. Ensure you have observed discharge data for calibration\n",
    "2. Set appropriate parameter ranges based on literature or expert knowledge\n",
    "3. Choose an appropriate objective function (KGE, NSE, RMSE, etc.)\n",
    "4. Run the calibration with a sufficient number of trials (typically 100-1000)\n",
    "5. Analyze the results and apply the best parameters\n",
    "\n",
    "```python\n",
    "# Example of full calibration\n",
    "study = run_calibration_example(use_real_optimization=True, n_trials=100, n_jobs=4)\n",
    "\n",
    "# Visualize results\n",
    "visualize_optuna_results(study)\n",
    "\n",
    "# Apply calibrated parameters\n",
    "calibrated_outputs = apply_calibrated_parameters(\n",
    "    study=study,\n",
    "    dem_shape=dem_array.shape,\n",
    "    conceptual_model=conceptual_model,\n",
    "    dem_path=DEM,\n",
    "    flow_acc=flow_acc,\n",
    "    flow_acc_plan=flow_acc_plan,\n",
    "    sp_prec=sp_prec,\n",
    "    sp_et=sp_et,\n",
    "    sp_temp=sp_temp,\n",
    "    p2=p2,\n",
    "    observed_q=observed_q\n",
    ")\n",
    "```\n",
    "\n",
    "You can also save the Optuna study to a database for persistence and later analysis:\n",
    "\n",
    "```python\n",
    "# Create study with database storage\n",
    "study = optuna.create_study(\n",
    "    study_name=\"hbv_calibration\",\n",
    "    storage=\"sqlite:///hbv_calibration.db\",\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# Load existing study\n",
    "existing_study = optuna.load_study(\n",
    "    study_name=\"hbv_calibration\",\n",
    "    storage=\"sqlite:///hbv_calibration.db\"\n",
    ")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
